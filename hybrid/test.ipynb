{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c324c75f-1236-43bf-8d9a-37000071e16b",
   "metadata": {},
   "source": [
    "### 모델 훈련\n",
    "개별 파일(MF.py, KNN.py)에서도 훈련이 가능하지만, 최상위 모듈인 train.py를 사용하여 학습을 진행할 수 있습니다.</br>\n",
    "train.py 모듈을 터미널에서 실행하는 것으로 학습할 수 있습니다.</br>\n",
    "train.py와 함께 사용할 수 있는 arguments들은 다음과 같습니다.</br>\n",
    "\n",
    "**mf 모델 학습용 arguments**\n",
    "- --mf : Matrix Factorization 모델의 학습 여부를 결정하는 인자입니다. --mf 를 입력하는 경우 학습을 진행하며, --no-mf를 입력하는 경우 해당 모델의 학습을 진행하지 않습니다.(입력하지 않았을 경우에는 학습 진행을 하도록 되어 있습니다.)\n",
    "- -k : Matrix Factorization 행렬의 크기를 결정하는 인자값입니다. (default = 200)\n",
    "- -e 또는 --epochs : mf 모델의 학습 횟수를 결정하는 인자입니다. (default = 1)\n",
    "- -b 또는 --batch_size : 학습 시 사용하는 batch_size를 결정하는 인자입니다.(default = 512)\n",
    "\n",
    "**knn 모델 학습용 arguments**\n",
    "- --knn : 최근접 이웃을 활용한 콘텐츠 기반 필터링 모델의 학습 여부를 결정하는 인자입니다. --knn을 입력하는 경우 학습을 진행하며, word2vec 모델과 cbf_data, knn모델을 models 폴더 경로에 생성합니다.(이미 존재하는 경우에는 업데이트) --no-knn을 입력하면 해당 모델의 학습을 진행하지 않습니다.(입력하지 않았을 경우에는 학습 진행을 하도록 되어 있습니다.)\n",
    "- --vector_size : word2vec 학습에 생성하는 행렬 차원의 수를 결정하는 인자입니다.(default = 100)\n",
    "- --pretrained : 영화 장르 임베딩을 적용할 때 사용하는 gensim의 사전학습 모델을 결정하는 인자입니다. (default = 'glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be019fe2-ef34-45b0-b31b-aa009fbdf24d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1/1251 [..............................] - ETA: 7:05 - loss: 14.3132\n",
      "   7/1251 [..............................] - ETA: 12s - loss: 14.2923 \n",
      "  13/1251 [..............................] - ETA: 12s - loss: 14.1496\n",
      "  19/1251 [..............................] - ETA: 12s - loss: 14.1277\n",
      "  25/1251 [..............................] - ETA: 11s - loss: 14.1340\n",
      "  31/1251 [..............................] - ETA: 11s - loss: 14.0876\n",
      "  37/1251 [..............................] - ETA: 11s - loss: 14.0822\n",
      "  43/1251 [>.............................] - ETA: 11s - loss: 14.0795\n",
      "  49/1251 [>.............................] - ETA: 11s - loss: 14.0664\n",
      "  55/1251 [>.............................] - ETA: 11s - loss: 14.0841\n",
      "  61/1251 [>.............................] - ETA: 11s - loss: 14.1011\n",
      "  66/1251 [>.............................] - ETA: 11s - loss: 14.1056\n",
      "  72/1251 [>.............................] - ETA: 11s - loss: 14.1016\n",
      "  77/1251 [>.............................] - ETA: 11s - loss: 14.1246\n",
      "  83/1251 [>.............................] - ETA: 11s - loss: 14.1164\n",
      "  88/1251 [=>............................] - ETA: 11s - loss: 14.1123\n",
      "  94/1251 [=>............................] - ETA: 11s - loss: 14.0994\n",
      " 100/1251 [=>............................] - ETA: 11s - loss: 14.0967\n",
      " 105/1251 [=>............................] - ETA: 11s - loss: 14.0949\n",
      " 111/1251 [=>............................] - ETA: 11s - loss: 14.1082\n",
      " 117/1251 [=>............................] - ETA: 11s - loss: 14.1041\n",
      " 123/1251 [=>............................] - ETA: 11s - loss: 14.1089\n",
      " 129/1251 [==>...........................] - ETA: 10s - loss: 14.1244\n",
      " 135/1251 [==>...........................] - ETA: 10s - loss: 14.1271\n",
      " 140/1251 [==>...........................] - ETA: 10s - loss: 14.1248\n",
      " 145/1251 [==>...........................] - ETA: 10s - loss: 14.1267\n",
      " 150/1251 [==>...........................] - ETA: 10s - loss: 14.1239\n",
      " 156/1251 [==>...........................] - ETA: 10s - loss: 14.1189\n",
      " 161/1251 [==>...........................] - ETA: 10s - loss: 14.1200\n",
      " 167/1251 [===>..........................] - ETA: 10s - loss: 14.1260\n",
      " 173/1251 [===>..........................] - ETA: 10s - loss: 14.1163\n",
      " 179/1251 [===>..........................] - ETA: 10s - loss: 14.1099\n",
      " 184/1251 [===>..........................] - ETA: 10s - loss: 14.1014\n",
      " 189/1251 [===>..........................] - ETA: 10s - loss: 14.1028\n",
      " 194/1251 [===>..........................] - ETA: 10s - loss: 14.0971\n",
      " 200/1251 [===>..........................] - ETA: 10s - loss: 14.0979\n",
      " 206/1251 [===>..........................] - ETA: 10s - loss: 14.0868\n",
      " 211/1251 [====>.........................] - ETA: 10s - loss: 14.0819\n",
      " 216/1251 [====>.........................] - ETA: 10s - loss: 14.0803\n",
      " 221/1251 [====>.........................] - ETA: 10s - loss: 14.0762\n",
      " 227/1251 [====>.........................] - ETA: 10s - loss: 14.0764\n",
      " 232/1251 [====>.........................] - ETA: 10s - loss: 14.0713\n",
      " 238/1251 [====>.........................] - ETA: 10s - loss: 14.0635\n",
      " 244/1251 [====>.........................] - ETA: 10s - loss: 14.0548\n",
      " 249/1251 [====>.........................] - ETA: 9s - loss: 14.0564 \n",
      " 255/1251 [=====>........................] - ETA: 9s - loss: 14.0537\n",
      " 261/1251 [=====>........................] - ETA: 9s - loss: 14.0502\n",
      " 267/1251 [=====>........................] - ETA: 9s - loss: 14.0490\n",
      " 272/1251 [=====>........................] - ETA: 9s - loss: 14.0425\n",
      " 277/1251 [=====>........................] - ETA: 9s - loss: 14.0344\n",
      " 282/1251 [=====>........................] - ETA: 9s - loss: 14.0252\n",
      " 287/1251 [=====>........................] - ETA: 9s - loss: 14.0175\n",
      " 292/1251 [======>.......................] - ETA: 9s - loss: 14.0046\n",
      " 297/1251 [======>.......................] - ETA: 9s - loss: 13.9965\n",
      " 302/1251 [======>.......................] - ETA: 9s - loss: 13.9852\n",
      " 307/1251 [======>.......................] - ETA: 9s - loss: 13.9733\n",
      " 312/1251 [======>.......................] - ETA: 9s - loss: 13.9593\n",
      " 318/1251 [======>.......................] - ETA: 9s - loss: 13.9404\n",
      " 324/1251 [======>.......................] - ETA: 9s - loss: 13.9182\n",
      " 330/1251 [======>.......................] - ETA: 9s - loss: 13.8977\n",
      " 336/1251 [=======>......................] - ETA: 9s - loss: 13.8738\n",
      " 341/1251 [=======>......................] - ETA: 9s - loss: 13.8517\n",
      " 346/1251 [=======>......................] - ETA: 9s - loss: 13.8326\n",
      " 351/1251 [=======>......................] - ETA: 9s - loss: 13.8108\n",
      " 356/1251 [=======>......................] - ETA: 9s - loss: 13.7854\n",
      " 361/1251 [=======>......................] - ETA: 8s - loss: 13.7599\n",
      " 366/1251 [=======>......................] - ETA: 8s - loss: 13.7313\n",
      " 371/1251 [=======>......................] - ETA: 8s - loss: 13.7009\n",
      " 377/1251 [========>.....................] - ETA: 8s - loss: 13.6603\n",
      " 383/1251 [========>.....................] - ETA: 8s - loss: 13.6162\n",
      " 389/1251 [========>.....................] - ETA: 8s - loss: 13.5707\n",
      " 395/1251 [========>.....................] - ETA: 8s - loss: 13.5209\n",
      " 401/1251 [========>.....................] - ETA: 8s - loss: 13.4645\n",
      " 407/1251 [========>.....................] - ETA: 8s - loss: 13.4035\n",
      " 413/1251 [========>.....................] - ETA: 8s - loss: 13.3409\n",
      " 419/1251 [=========>....................] - ETA: 8s - loss: 13.2767\n",
      " 425/1251 [=========>....................] - ETA: 8s - loss: 13.2101\n",
      " 431/1251 [=========>....................] - ETA: 8s - loss: 13.1354\n",
      " 437/1251 [=========>....................] - ETA: 8s - loss: 13.0617\n",
      " 443/1251 [=========>....................] - ETA: 8s - loss: 12.9861\n",
      " 449/1251 [=========>....................] - ETA: 8s - loss: 12.9072\n",
      " 455/1251 [=========>....................] - ETA: 7s - loss: 12.8263\n",
      " 461/1251 [==========>...................] - ETA: 7s - loss: 12.7442\n",
      " 467/1251 [==========>...................] - ETA: 7s - loss: 12.6576\n",
      " 473/1251 [==========>...................] - ETA: 7s - loss: 12.5693\n",
      " 479/1251 [==========>...................] - ETA: 7s - loss: 12.4789\n",
      " 485/1251 [==========>...................] - ETA: 7s - loss: 12.3865\n",
      " 491/1251 [==========>...................] - ETA: 7s - loss: 12.2980\n",
      " 497/1251 [==========>...................] - ETA: 7s - loss: 12.2058\n",
      " 503/1251 [===========>..................] - ETA: 7s - loss: 12.1115\n",
      " 509/1251 [===========>..................] - ETA: 7s - loss: 12.0182\n",
      " 515/1251 [===========>..................] - ETA: 7s - loss: 11.9236\n",
      " 521/1251 [===========>..................] - ETA: 7s - loss: 11.8306\n",
      " 527/1251 [===========>..................] - ETA: 7s - loss: 11.7378\n",
      " 533/1251 [===========>..................] - ETA: 7s - loss: 11.6445\n",
      " 539/1251 [===========>..................] - ETA: 7s - loss: 11.5507\n",
      " 545/1251 [============>.................] - ETA: 7s - loss: 11.4592\n",
      " 551/1251 [============>.................] - ETA: 6s - loss: 11.3679\n",
      " 557/1251 [============>.................] - ETA: 6s - loss: 11.2769\n",
      " 563/1251 [============>.................] - ETA: 6s - loss: 11.1880\n",
      " 569/1251 [============>.................] - ETA: 6s - loss: 11.0991\n",
      " 575/1251 [============>.................] - ETA: 6s - loss: 11.0118\n",
      " 581/1251 [============>.................] - ETA: 6s - loss: 10.9239\n",
      " 587/1251 [=============>................] - ETA: 6s - loss: 10.8376\n",
      " 593/1251 [=============>................] - ETA: 6s - loss: 10.7531\n",
      " 599/1251 [=============>................] - ETA: 6s - loss: 10.6684\n",
      " 605/1251 [=============>................] - ETA: 6s - loss: 10.5869\n",
      " 611/1251 [=============>................] - ETA: 6s - loss: 10.5053\n",
      " 617/1251 [=============>................] - ETA: 6s - loss: 10.4243\n",
      " 623/1251 [=============>................] - ETA: 6s - loss: 10.3440\n",
      " 629/1251 [==============>...............] - ETA: 6s - loss: 10.2646\n",
      " 635/1251 [==============>...............] - ETA: 6s - loss: 10.1874\n",
      " 641/1251 [==============>...............] - ETA: 6s - loss: 10.1104\n",
      " 647/1251 [==============>...............] - ETA: 5s - loss: 10.0336\n",
      " 652/1251 [==============>...............] - ETA: 5s - loss: 9.9713 \n",
      " 658/1251 [==============>...............] - ETA: 5s - loss: 9.8970\n",
      " 664/1251 [==============>...............] - ETA: 5s - loss: 9.8239\n",
      " 670/1251 [===============>..............] - ETA: 5s - loss: 9.7522\n",
      " 676/1251 [===============>..............] - ETA: 5s - loss: 9.6813\n",
      " 682/1251 [===============>..............] - ETA: 5s - loss: 9.6112\n",
      " 688/1251 [===============>..............] - ETA: 5s - loss: 9.5421\n",
      " 694/1251 [===============>..............] - ETA: 5s - loss: 9.4743\n",
      " 700/1251 [===============>..............] - ETA: 5s - loss: 9.4076\n",
      " 706/1251 [===============>..............] - ETA: 5s - loss: 9.3409\n",
      " 711/1251 [================>.............] - ETA: 5s - loss: 9.2865\n",
      " 716/1251 [================>.............] - ETA: 5s - loss: 9.2329\n",
      " 721/1251 [================>.............] - ETA: 5s - loss: 9.1795\n",
      " 726/1251 [================>.............] - ETA: 5s - loss: 9.1268\n",
      " 732/1251 [================>.............] - ETA: 5s - loss: 9.0651\n",
      " 738/1251 [================>.............] - ETA: 5s - loss: 9.0035\n",
      " 744/1251 [================>.............] - ETA: 4s - loss: 8.9424\n",
      " 750/1251 [================>.............] - ETA: 4s - loss: 8.8822\n",
      " 756/1251 [=================>............] - ETA: 4s - loss: 8.8236\n",
      " 762/1251 [=================>............] - ETA: 4s - loss: 8.7653\n",
      " 768/1251 [=================>............] - ETA: 4s - loss: 8.7075\n",
      " 774/1251 [=================>............] - ETA: 4s - loss: 8.6508\n",
      " 780/1251 [=================>............] - ETA: 4s - loss: 8.5950\n",
      " 786/1251 [=================>............] - ETA: 4s - loss: 8.5396\n",
      " 791/1251 [=================>............] - ETA: 4s - loss: 8.4938\n",
      " 796/1251 [==================>...........] - ETA: 4s - loss: 8.4491\n",
      " 801/1251 [==================>...........] - ETA: 4s - loss: 8.4045\n",
      " 806/1251 [==================>...........] - ETA: 4s - loss: 8.3601\n",
      " 812/1251 [==================>...........] - ETA: 4s - loss: 8.3082\n",
      " 818/1251 [==================>...........] - ETA: 4s - loss: 8.2565\n",
      " 824/1251 [==================>...........] - ETA: 4s - loss: 8.2058\n",
      " 830/1251 [==================>...........] - ETA: 4s - loss: 8.1553\n",
      " 836/1251 [===================>..........] - ETA: 4s - loss: 8.1054\n",
      " 842/1251 [===================>..........] - ETA: 4s - loss: 8.0570\n",
      " 847/1251 [===================>..........] - ETA: 3s - loss: 8.0162\n",
      " 852/1251 [===================>..........] - ETA: 3s - loss: 7.9762\n",
      " 857/1251 [===================>..........] - ETA: 3s - loss: 7.9367\n",
      " 863/1251 [===================>..........] - ETA: 3s - loss: 7.8902\n",
      " 869/1251 [===================>..........] - ETA: 3s - loss: 7.8442\n",
      " 875/1251 [===================>..........] - ETA: 3s - loss: 7.7987\n",
      " 880/1251 [====================>.........] - ETA: 3s - loss: 7.7613\n",
      " 884/1251 [====================>.........] - ETA: 3s - loss: 7.7315\n",
      " 889/1251 [====================>.........] - ETA: 3s - loss: 7.6945\n",
      " 894/1251 [====================>.........] - ETA: 3s - loss: 7.6579\n",
      " 899/1251 [====================>.........] - ETA: 3s - loss: 7.6215\n",
      " 905/1251 [====================>.........] - ETA: 3s - loss: 7.5788\n",
      " 910/1251 [====================>.........] - ETA: 3s - loss: 7.5433\n",
      " 916/1251 [====================>.........] - ETA: 3s - loss: 7.5010\n",
      " 922/1251 [=====================>........] - ETA: 3s - loss: 7.4598\n",
      " 927/1251 [=====================>........] - ETA: 3s - loss: 7.4256\n",
      " 931/1251 [=====================>........] - ETA: 3s - loss: 7.3985\n",
      " 935/1251 [=====================>........] - ETA: 3s - loss: 7.3717\n",
      " 939/1251 [=====================>........] - ETA: 3s - loss: 7.3449\n",
      " 943/1251 [=====================>........] - ETA: 3s - loss: 7.3183\n",
      " 947/1251 [=====================>........] - ETA: 3s - loss: 7.2922\n",
      " 951/1251 [=====================>........] - ETA: 3s - loss: 7.2659\n",
      " 955/1251 [=====================>........] - ETA: 2s - loss: 7.2400\n",
      " 959/1251 [=====================>........] - ETA: 2s - loss: 7.2146\n",
      " 963/1251 [======================>.......] - ETA: 2s - loss: 7.1892\n",
      " 967/1251 [======================>.......] - ETA: 2s - loss: 7.1637\n",
      " 971/1251 [======================>.......] - ETA: 2s - loss: 7.1386\n",
      " 975/1251 [======================>.......] - ETA: 2s - loss: 7.1138\n",
      " 979/1251 [======================>.......] - ETA: 2s - loss: 7.0892\n",
      " 983/1251 [======================>.......] - ETA: 2s - loss: 7.0646\n",
      " 988/1251 [======================>.......] - ETA: 2s - loss: 7.0344\n",
      " 994/1251 [======================>.......] - ETA: 2s - loss: 6.9982\n",
      "1000/1251 [======================>.......] - ETA: 2s - loss: 6.9628\n",
      "1005/1251 [=======================>......] - ETA: 2s - loss: 6.9332\n",
      "1010/1251 [=======================>......] - ETA: 2s - loss: 6.9043\n",
      "1015/1251 [=======================>......] - ETA: 2s - loss: 6.8754\n",
      "1020/1251 [=======================>......] - ETA: 2s - loss: 6.8469\n",
      "1025/1251 [=======================>......] - ETA: 2s - loss: 6.8187\n",
      "1030/1251 [=======================>......] - ETA: 2s - loss: 6.7903\n",
      "1035/1251 [=======================>......] - ETA: 2s - loss: 6.7624\n",
      "1040/1251 [=======================>......] - ETA: 2s - loss: 6.7349\n",
      "1044/1251 [========================>.....] - ETA: 2s - loss: 6.7129\n",
      "1048/1251 [========================>.....] - ETA: 2s - loss: 6.6912\n",
      "1051/1251 [========================>.....] - ETA: 2s - loss: 6.6749\n",
      "1055/1251 [========================>.....] - ETA: 2s - loss: 6.6533\n",
      "1059/1251 [========================>.....] - ETA: 1s - loss: 6.6321\n",
      "1063/1251 [========================>.....] - ETA: 1s - loss: 6.6109\n",
      "1068/1251 [========================>.....] - ETA: 1s - loss: 6.5846\n",
      "1073/1251 [========================>.....] - ETA: 1s - loss: 6.5586\n",
      "1078/1251 [========================>.....] - ETA: 1s - loss: 6.5330\n",
      "1083/1251 [========================>.....] - ETA: 1s - loss: 6.5072\n",
      "1088/1251 [=========================>....] - ETA: 1s - loss: 6.4819\n",
      "1093/1251 [=========================>....] - ETA: 1s - loss: 6.4569\n",
      "1098/1251 [=========================>....] - ETA: 1s - loss: 6.4320\n",
      "1103/1251 [=========================>....] - ETA: 1s - loss: 6.4072\n",
      "1108/1251 [=========================>....] - ETA: 1s - loss: 6.3829\n",
      "1113/1251 [=========================>....] - ETA: 1s - loss: 6.3590\n",
      "1118/1251 [=========================>....] - ETA: 1s - loss: 6.3346\n",
      "1123/1251 [=========================>....] - ETA: 1s - loss: 6.3108\n",
      "1128/1251 [==========================>...] - ETA: 1s - loss: 6.2873\n",
      "1133/1251 [==========================>...] - ETA: 1s - loss: 6.2641\n",
      "1138/1251 [==========================>...] - ETA: 1s - loss: 6.2407\n",
      "1143/1251 [==========================>...] - ETA: 1s - loss: 6.2175\n",
      "1148/1251 [==========================>...] - ETA: 1s - loss: 6.1947\n",
      "1153/1251 [==========================>...] - ETA: 1s - loss: 6.1720\n",
      "1158/1251 [==========================>...] - ETA: 0s - loss: 6.1493\n",
      "1164/1251 [==========================>...] - ETA: 0s - loss: 6.1225\n",
      "1169/1251 [===========================>..] - ETA: 0s - loss: 6.1005\n",
      "1175/1251 [===========================>..] - ETA: 0s - loss: 6.0744\n",
      "1181/1251 [===========================>..] - ETA: 0s - loss: 6.0486\n",
      "1185/1251 [===========================>..] - ETA: 0s - loss: 6.0315\n",
      "1189/1251 [===========================>..] - ETA: 0s - loss: 6.0146\n",
      "1193/1251 [===========================>..] - ETA: 0s - loss: 5.9977\n",
      "1197/1251 [===========================>..] - ETA: 0s - loss: 5.9809\n",
      "1201/1251 [===========================>..] - ETA: 0s - loss: 5.9641\n",
      "1207/1251 [===========================>..] - ETA: 0s - loss: 5.9393\n",
      "1213/1251 [============================>.] - ETA: 0s - loss: 5.9147\n",
      "1219/1251 [============================>.] - ETA: 0s - loss: 5.8904\n",
      "1223/1251 [============================>.] - ETA: 0s - loss: 5.8741\n",
      "1228/1251 [============================>.] - ETA: 0s - loss: 5.8541\n",
      "1232/1251 [============================>.] - ETA: 0s - loss: 5.8383\n",
      "1237/1251 [============================>.] - ETA: 0s - loss: 5.8186\n",
      "1242/1251 [============================>.] - ETA: 0s - loss: 5.7989\n",
      "1247/1251 [============================>.] - ETA: 0s - loss: 5.7793\n",
      "1251/1251 [==============================] - 14s 11ms/step - loss: 5.7668 - val_loss: 0.9398\n",
      "---Saving model---\n",
      "Save Complete.\n",
      "---Tokenizing...---\n",
      "Tokenizing Complete.\n",
      "---w2v Training...---\n",
      "(4839, 100)\n",
      "w2v Training Complete.\n",
      "---pre-trained w2v loading...---\n",
      "loading Complete.\n",
      "---knn Training...---\n",
      "---knn Done.---\n"
     ]
    }
   ],
   "source": [
    "#CLI\n",
    "#mf모델만 3 epochs로 학습하라는 명령어(knn 모델은 학습하지 않음)\n",
    "#두가지 모델을 전무 학습시키고 싶다면 !python trian.py 명령어를 사용하시면 됩니다.\n",
    "!python train.py\n",
    "#--no-knn -e 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a567502-f546-4f67-91d2-3ac8a3cfba11",
   "metadata": {},
   "source": [
    "### 인기도 기반 추천 시스템 테스트\n",
    "베이스라인 모델의 인기도 기반 추천은 사용자들이 가장 많이 평점을 남긴 영화 순으로 추천하도록 설계되어 있습니다.</br>\n",
    "관련 코드는 models 폴더의 impersonal.py 코드에 작성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce1dae94-bc99-4e7f-9bf5-efaf929ec29e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2858, 260, 1196, 1210, 480, 2028, 589, 2571, 1270, 593]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.impersonal import popular\n",
    "popular(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7d5c0-1ae1-46a3-b90a-74dac0ae5699",
   "metadata": {},
   "source": [
    "### 협업 필터링 모델 테스트\n",
    "Matrix Factorization 기반 모델 코드의 경우 train.py를 통해 학습한 mf.h5 파일을 로드하여 예측을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e69e7450-f9ab-48e9-8c69-d807439ff616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models.MF import MF\n",
    "\n",
    "mf = MF('./models/mf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93daed87-1a6b-4fa4-a9a5-fb389bfc2a83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[858, 527, 1148, 908, 260, 1198, 318, 930, 50, 2762]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userid = 1\n",
    "mf.predict(userid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6ecf3-c2a6-4573-bcd2-be1e9b971b2c",
   "metadata": {},
   "source": [
    "### 콘텐츠 기반 필터링 모델 테스트\n",
    "최근접 이웃 알고리즘을 활용한 콘텐츠 기반 필터링 모델의 경우 train.py를 통해 학습한 knn.joblib 파일을 로드하여 예측을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "135ddc53-3b3a-48fd-bdb0-2905b8cc4b07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models.KNN import KNN\n",
    "\n",
    "knn = KNN('models/knn.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a21c72f-76b0-4e43-b9c7-b3d9056cbd3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2081, 2080, 2138,  239, 1566,  919, 2102,  588, 2078,   48],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_ID = 1\n",
    "TOP_NUM=10\n",
    "knn.predict(USER_ID, TOP_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3321ba1",
   "metadata": {},
   "source": [
    "### 하이브리드 모델 테스트\n",
    "최근접 이웃 알고리즘과 협업필터링을 병합한 모델을 통해 학습하고 예측을 진행<BR>\n",
    "독립된 추천 결과를 조합 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c944a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.hybrid import Hybrid_1, Hybrid_2\n",
    "import numpy as np\n",
    "from models.MF import MF\n",
    "from models.KNN import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4526aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2081, 858, 2080, 527, 2138, 1148, 239, 908, 1566, 260],\n",
       " array([2081, 2080, 2138,  239, 1566,  919, 2102,  588, 2078,   48],\n",
       "       dtype=int64),\n",
       " [858, 527, 1148, 908, 260, 1198, 318, 930, 50, 2762])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 모델 생성\n",
    "mf = MF('./models/mf.h5')\n",
    "knn = KNN('models/knn.joblib')\n",
    "alpha = 0.5  # 가중치 조절 파라미터(KNN : alpha , MF : 1-alpha)\n",
    "hybrid_c = Hybridcombine(knn, mf, alpha)\n",
    "USER_ID = 1\n",
    "TOP_NUM = 10\n",
    "hybrid_c.predict(USER_ID, TOP_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7062a9",
   "metadata": {},
   "source": [
    "#### 콘텐츠 기반 모델로 출력한 user에 대한 영화 top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcd4d340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Little Mermaid, The (1989)',\n",
       " 'Godfather, The (1972)',\n",
       " 'Lady and the Tramp (1955)',\n",
       " \"Schindler's List (1993)\",\n",
       " 'Watership Down (1978)',\n",
       " 'Wrong Trousers, The (1993)',\n",
       " 'Goofy Movie, A (1995)',\n",
       " 'North by Northwest (1959)',\n",
       " 'Hercules (1997)',\n",
       " 'Star Wars: Episode IV - A New Hope (1977)']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.Dataloader import load_ratings, load_movies\n",
    "\n",
    "DATA_PATH = \"./datasets/\"\n",
    "movies_df = load_movies(DATA_PATH)\n",
    "\n",
    "predicted_values, knn_r, mf_r = hybrid_c.predict(target_user_id, TOP_NUM)\n",
    "m_titles=[]\n",
    "for i in predicted_values:\n",
    "    m_title =movies_df[movies_df['movieId'] ==i]['title'].item()\n",
    "    m_titles.append(m_title)\n",
    "m_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf6945",
   "metadata": {},
   "source": [
    "### 콘텐츠 기반 정보를 협업 필터링에 적용\n",
    "사용자의 평가점수가 아닌 콘텐츠기반 사용자 프로파일을 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d1d760",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m hybrid_model \u001b[39m=\u001b[39m Hybrid_2(knn_model, mf_model)\n\u001b[0;32m     21\u001b[0m \u001b[39m# 데이터 로딩 및 처리\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m hybrid_model\u001b[39m.\u001b[39;49mload_data(users_df, movies_df, ratings_df)\n\u001b[0;32m     24\u001b[0m \u001b[39m# 특정 사용자 ID 설정\u001b[39;00m\n\u001b[0;32m     25\u001b[0m target_user_id \u001b[39m=\u001b[39m \u001b[39m1004\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jain3\\OneDrive\\Desktop\\AI\\Team_project_2\\hybrid\\models\\hybrid.py:60\u001b[0m, in \u001b[0;36mHybrid_2.load_data\u001b[1;34m(self, users_df, movies_df, ratings_df)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_movie_similarity \u001b[39m=\u001b[39m {}  \u001b[39m# 사용자별 영화 벡터 유사도를 저장할 딕셔너리\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39mfor\u001b[39;00m user_id \u001b[39min\u001b[39;00m users_df[\u001b[39m'\u001b[39m\u001b[39muserId\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m---> 60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_movie_similarity[user_id] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mknn_model\u001b[39m.\u001b[39;49mcalculate_movie_similarity(user_id)\n\u001b[0;32m     62\u001b[0m \u001b[39m# MF 모델 훈련 및 예측\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmf_model\u001b[39m.\u001b[39mtrain(users_df, movies_df, ratings_df)\n",
      "File \u001b[1;32mc:\\Users\\jain3\\OneDrive\\Desktop\\AI\\Team_project_2\\hybrid\\models\\KNN.py:50\u001b[0m, in \u001b[0;36mKNN.calculate_movie_similarity\u001b[1;34m(self, user_id)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39m#data load\u001b[39;00m\n\u001b[0;32m     49\u001b[0m cbf_data \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mmodels/cbf_data.joblib\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m ratings_df \u001b[39m=\u001b[39m load_ratings(\u001b[39m'\u001b[39;49m\u001b[39mdatasets/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     52\u001b[0m \u001b[39m# 사용자가 시청한 영화 목록 호출\u001b[39;00m\n\u001b[0;32m     53\u001b[0m movie_list \u001b[39m=\u001b[39m ratings_df[ratings_df[\u001b[39m'\u001b[39m\u001b[39muserId\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m user_id][\u001b[39m'\u001b[39m\u001b[39mmovieId\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\jain3\\OneDrive\\Desktop\\AI\\Team_project_2\\hybrid\\utils\\Dataloader.py:6\u001b[0m, in \u001b[0;36mload_ratings\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_ratings\u001b[39m(path):\n\u001b[0;32m      5\u001b[0m     COL_NAME \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39muserId\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmovieId\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path,\u001b[39m\"\u001b[39;49m\u001b[39mratings.dat\u001b[39;49m\u001b[39m\"\u001b[39;49m),sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m::\u001b[39;49m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, engine\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpython\u001b[39;49m\u001b[39m'\u001b[39;49m, names\u001b[39m=\u001b[39;49mCOL_NAME)\n\u001b[0;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\jain3\\anaconda3\\envs\\tp2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\jain3\\anaconda3\\envs\\tp2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\jain3\\anaconda3\\envs\\tp2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1705\u001b[0m         nrows\n\u001b[0;32m   1706\u001b[0m     )\n\u001b[0;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\jain3\\anaconda3\\envs\\tp2\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:251\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\n\u001b[0;32m    246\u001b[0m     \u001b[39mself\u001b[39m, rows: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    247\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[\n\u001b[0;32m    248\u001b[0m     Index \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m, Sequence[Hashable] \u001b[39m|\u001b[39m MultiIndex, Mapping[Hashable, ArrayLike]\n\u001b[0;32m    249\u001b[0m ]:\n\u001b[0;32m    250\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m         content \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_lines(rows)\n\u001b[0;32m    252\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mc:\\Users\\jain3\\anaconda3\\envs\\tp2\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:1130\u001b[0m, in \u001b[0;36mPythonParser._get_lines\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m   1127\u001b[0m rows \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m   1129\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m     new_row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_iter_line(row_num\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos \u001b[39m+\u001b[39;49m rows \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m   1131\u001b[0m     rows \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m new_row \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jain3\\anaconda3\\envs\\tp2\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:795\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[1;34m(self, row_num)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    793\u001b[0m     \u001b[39m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[39;00m\n\u001b[0;32m    794\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m    796\u001b[0m     \u001b[39m# for mypy\u001b[39;00m\n\u001b[0;32m    797\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(line, \u001b[39mlist\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 필요 라이브러리\n",
    "import numpy as np\n",
    "from models.KNN import KNN\n",
    "from models.MF import MF\n",
    "import joblib\n",
    "from utils.Dataloader import load_ratings, load_movies, load_users\n",
    "\n",
    "# 모델 로드 및 초기화\n",
    "knn_model = KNN('models/knn.joblib')\n",
    "mf_model = MF('./models/mf.h5')\n",
    "\n",
    "# 사용자, 영화, 평점 데이터 로딩 (users_df, movies_df, ratings_df)\n",
    "DATA_PATH = \"./datasets/\"\n",
    "users_df = load_users(DATA_PATH)\n",
    "movies_df = load_movies(DATA_PATH)\n",
    "ratings_df = load_ratings(DATA_PATH)\n",
    "\n",
    "# Hybrid 모델 생성\n",
    "hybrid_model = Hybrid_2(knn_model, mf_model)\n",
    "\n",
    "# 데이터 로딩 및 처리\n",
    "hybrid_model.load_data(users_df, movies_df, ratings_df)\n",
    "\n",
    "# 특정 사용자 ID 설정\n",
    "target_user_id = 1004\n",
    "\n",
    "# 특정 사용자의 추천 목록 출력\n",
    "top_num = 10\n",
    "recommended_movies = hybrid_model.recommend(target_user_id, top_num)\n",
    "print(f\"User {target_user_id} Recommendations (Hybrid):\", recommended_movies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9d288",
   "metadata": {},
   "source": [
    "### Surprise 활용 recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba559a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Surprise_hybrid import SHybridRecommender\n",
    "from utils.Dataloader import load_ratings, load_movies, load_users\n",
    "\n",
    "DATA_PATH = \"./datasets/\"\n",
    "users_df = load_users(DATA_PATH)\n",
    "movies_df = load_movies(DATA_PATH)\n",
    "ratings_df = load_ratings(DATA_PATH)\n",
    "\n",
    "hybrid_recommender = SHybridRecommender(users_df, movies_df, ratings_df)\n",
    "\n",
    "user_id = 1004\n",
    "recommended_movie_indices = hybrid_recommender.hybrid_recommend(user_id, num_recommendations=10)\n",
    "print(\"Recommended Movies:\")\n",
    "for idx, movie_idx in enumerate(recommended_movie_indices, start=1):\n",
    "    movie_title = movies_df.iloc[movie_idx]['movie_title']\n",
    "    print(f\"{idx}. {movie_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e396d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, genres]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.Surprise_hybrid import EnsembleRecommender\n",
    "import numpy as np\n",
    "from utils.Dataloader import load_ratings, load_movies, load_users\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "DATA_PATH = \"./datasets/\"\n",
    "rating_df = load_ratings(DATA_PATH)\n",
    "movie_df = load_movies(DATA_PATH)\n",
    "\n",
    "user_ids = rating_df[\"userId\"].unique().tolist() \n",
    "num_all_user = len(user_ids)\n",
    "\n",
    "# randomly select 20% users from rating dataset \n",
    "np.random.seed(123)\n",
    "rand_userid = np.random.choice(user_ids, size=int(num_all_user * 0.1), replace=False)\n",
    "sample_df = rating_df.loc[rating_df['userId'].isin(rand_userid)]\n",
    "\n",
    "# Create user-item rating matrix\n",
    "def movie_use_matrix_pivot(df_):\n",
    "    mu_matrix = df_.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "    # compress original matrix\n",
    "    mu_matrix_cp = csr_matrix(mu_matrix.values)\n",
    "    return mu_matrix, mu_matrix_cp\n",
    "\n",
    "rating_matrix, rating_matrix_cp = movie_use_matrix_pivot(sample_df)\n",
    "\n",
    "# Create some dummy item vectors for illustration\n",
    "num_movies = len(sample_df['movieId'].unique())\n",
    "num_features = 10\n",
    "item_vector = np.random.rand(num_movies, num_features)\n",
    "\n",
    "# Initialize the EnsembleRecommender\n",
    "Ensemble = EnsembleRecommender(sample_df, movie_df, rating_matrix_cp, item_vector)\n",
    "\n",
    "# user 1004 has more than 150 ratings\n",
    "Ensemble.Recommend(1004)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6cbccc",
   "metadata": {},
   "source": [
    "### 평가지표 NDCG(수정 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cdaf1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1의 Top 10 평점 영화:\n",
      "1. 영화 ID: 1193, 평점: 5\n",
      "47. 영화 ID: 1029, 평점: 5\n",
      "41. 영화 ID: 1, 평점: 5\n",
      "19. 영화 ID: 3105, 평점: 5\n",
      "42. 영화 ID: 1961, 평점: 5\n",
      "24. 영화 ID: 527, 평점: 5\n",
      "38. 영화 ID: 1022, 평점: 5\n",
      "15. 영화 ID: 1035, 평점: 5\n",
      "26. 영화 ID: 48, 평점: 5\n",
      "46. 영화 ID: 1028, 평점: 5\n"
     ]
    }
   ],
   "source": [
    "from utils.Dataloader import load_ratings\n",
    "\n",
    "# 데이터 폴더 경로\n",
    "DATA_PATH = \"./datasets/\"\n",
    "\n",
    "# ratings 데이터 로드\n",
    "ratings_df = load_ratings(DATA_PATH)\n",
    "\n",
    "# 특정 user_id\n",
    "target_user_id = 1\n",
    "\n",
    "# 특정 user_id의 평점 데이터\n",
    "target_user_ratings = ratings_df[ratings_df['userId'] == target_user_id]\n",
    "\n",
    "# 평점을 기준으로 내림차순 정렬하여 top 10개 출력\n",
    "top_rated_movies = target_user_ratings.sort_values(by='rating', ascending=False).head(10)\n",
    "\n",
    "print(f\"User {target_user_id}의 Top 10 평점 영화:\")\n",
    "for rank, row in top_rated_movies.iterrows():\n",
    "    movie_id = row['movieId']\n",
    "    rating = row['rating']\n",
    "    print(f\"{rank+1}. 영화 ID: {movie_id}, 평점: {rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8a85c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1004의 NDCG@10: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 로드\n",
    "ratings_df = load_ratings('./datasets/')\n",
    "\n",
    "# 테스트를 위한 특정 user_id\n",
    "target_user_id = 1004\n",
    "\n",
    "# top N 영화 예측\n",
    "TOP_NUM = 10\n",
    "\n",
    "'''predicted_values, knn_r, mf_r = hybrid_c.predict(target_user_id, TOP_NUM)\n",
    "hybrid_predictions = predicted_values'''\n",
    "\n",
    "# 실제 평가 데이터 가져오기- 수정 필요\n",
    "actual_ratings = ratings_df[ratings_df['userId'] == target_user_id]\n",
    "actual_ratings = actual_ratings.sort_values(by='rating', ascending=False)\n",
    "\n",
    "# NDCG 계산\n",
    "def ndcg(actual, predicted, k):\n",
    "    idcg = sum(1 / (np.log2(rank + 2)) for rank in range(min(k, len(actual))))\n",
    "    dcg = sum(1 / (np.log2(rank + 2)) if movie_id in predicted else 0 for rank, (movie_id, _) in enumerate(actual.items()))\n",
    "    return dcg / idcg\n",
    "\n",
    "# NDCG 계산 및 출력\n",
    "print(f\"User {target_user_id}의 NDCG@{TOP_NUM}: {ndcg(actual_ratings['movieId'], hybrid_predictions, TOP_NUM):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfa508c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1004의 NDCG@10: 0.0000\n",
      "User 1004의 NDCG@10: 0.0000\n",
      "User 1004의 NDCG@10: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# NDCG 계산\n",
    "def ndcg(actual, predicted, k):\n",
    "    idcg = sum(1 / (np.log2(rank + 2)) for rank in range(min(k, len(actual))))\n",
    "    dcg = sum(1 / (np.log2(rank + 2)) if movie_id in predicted else 0 for rank, (movie_id, _) in enumerate(actual.items()))\n",
    "    return dcg / idcg\n",
    "\n",
    "# NDCG 계산 및 출력\n",
    "print(f\"User {target_user_id}의 NDCG@{TOP_NUM}: {ndcg(actual_ratings['movieId'], hybrid_predictions, TOP_NUM):.4f}\")\n",
    "print(f\"User {target_user_id}의 NDCG@{TOP_NUM}: {ndcg(actual_ratings['movieId'], knn_r, TOP_NUM):.4f}\")\n",
    "print(f\"User {target_user_id}의 NDCG@{TOP_NUM}: {ndcg(actual_ratings['movieId'], mf_r, TOP_NUM):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a569c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDCG 계산\n",
    "def ndcg(actual, predicted, k):\n",
    "    idcg = sum(1 / (np.log2(rank + 2)) for rank in range(min(k, len(actual))))\n",
    "    dcg = sum(1 / (np.log2(rank + 2)) if movie_id in predicted else 0 for rank, (movie_id, _) in enumerate(actual.iterrows()))\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abd64d85",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# NDCG 계산 및 출력\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUser \u001b[39m\u001b[39m{\u001b[39;00mtarget_user_id\u001b[39m}\u001b[39;00m\u001b[39m의 NDCG@\u001b[39m\u001b[39m{\u001b[39;00mTOP_NUM\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mndcg(actual_ratings\u001b[39m.\u001b[39;49mindex,\u001b[39m \u001b[39;49mhybrid_predictions,\u001b[39m \u001b[39;49mTOP_NUM)\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m, in \u001b[0;36mndcg\u001b[1;34m(actual, predicted, k)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mndcg\u001b[39m(actual, predicted, k):\n\u001b[0;32m      3\u001b[0m     idcg \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (np\u001b[39m.\u001b[39mlog2(rank \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m)) \u001b[39mfor\u001b[39;00m rank \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mmin\u001b[39m(k, \u001b[39mlen\u001b[39m(actual))))\n\u001b[1;32m----> 4\u001b[0m     dcg \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (np\u001b[39m.\u001b[39mlog2(rank \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m)) \u001b[39mif\u001b[39;00m movie_id \u001b[39min\u001b[39;00m predicted \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m rank, (movie_id, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(actual\u001b[39m.\u001b[39;49miterrows()))\n\u001b[0;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m dcg \u001b[39m/\u001b[39m idcg\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Index' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "# NDCG 계산 및 출력\n",
    "print(f\"User {target_user_id}의 NDCG@{TOP_NUM}: {ndcg(actual_ratings.index, hybrid_predictions, TOP_NUM):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "16dad16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1205 1215  258   70 2054 1210 2322  673 1264 1196]\n",
      "[1198, 260, 1036, 1200, 1196, 858, 318, 1240, 589, 1214]\n"
     ]
    }
   ],
   "source": [
    "knn_r = knn.predict(1004, 10)\n",
    "mf_r = mf.predict(1004, 10)\n",
    "print(knn_r)\n",
    "print(mf_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8111522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1205: 1.0, 1215: 0.5, 258: 0.3333333333333333, 70: 0.25, 2054: 0.2, 1210: 0.16666666666666666, 2322: 0.14285714285714285, 673: 0.125, 1264: 0.1111111111111111, 1196: 0.1}\n",
      "{1198: 1.0, 260: 0.5, 1036: 0.3333333333333333, 1200: 0.25, 1196: 0.2, 858: 0.16666666666666666, 318: 0.14285714285714285, 1240: 0.125, 589: 0.1111111111111111, 1214: 0.1}\n"
     ]
    }
   ],
   "source": [
    "knn_rank = {idx: 1 / (i + 1) for i, idx in enumerate(knn_r)}\n",
    "mf_rank = {idx: 1 / (i + 1) for i, idx in enumerate(mf_r)}\n",
    "print(knn_rank)\n",
    "print(mf_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "34c99ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1205: 0.5, 1215: 0.25, 258: 0.16666666666666666, 70: 0.125, 2054: 0.1, 1210: 0.08333333333333333, 2322: 0.07142857142857142, 673: 0.0625, 1264: 0.05555555555555555, 1196: 0.15000000000000002, 1198: 0.5, 260: 0.25, 1036: 0.16666666666666666, 1200: 0.125, 858: 0.08333333333333333, 318: 0.07142857142857142, 1240: 0.0625, 589: 0.05555555555555555, 1214: 0.05}\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "combined_scores = {}\n",
    "for idx, knn_rank in knn_rank.items():\n",
    "    combined_scores[idx] = combined_scores.get(idx, 0) + (alpha * knn_rank)\n",
    "for idx, mf_rank in mf_rank.items():\n",
    "    combined_scores[idx] = combined_scores.get(idx, 0) + ((1 - alpha) * mf_rank)\n",
    "\n",
    "print(combined_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "34508602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1205, 0.5), (1198, 0.5), (1215, 0.25), (260, 0.25), (258, 0.16666666666666666), (1036, 0.16666666666666666), (1196, 0.15000000000000002), (70, 0.125), (1200, 0.125), (2054, 0.1), (1210, 0.08333333333333333), (858, 0.08333333333333333), (2322, 0.07142857142857142), (318, 0.07142857142857142), (673, 0.0625), (1240, 0.0625), (1264, 0.05555555555555555), (589, 0.05555555555555555), (1214, 0.05)]\n"
     ]
    }
   ],
   "source": [
    "sorted_combined = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7afeaba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1205, 1198, 1215, 260, 258, 1036, 1196, 70, 1200, 2054]\n"
     ]
    }
   ],
   "source": [
    "top_10_indices = [idx for idx, _ in sorted_combined[:10]]\n",
    "print(top_10_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
